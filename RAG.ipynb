{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNB8r/bybAv11/14RdiZygL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hardik-kumar-10/GenAI-learnings/blob/main/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "H44Oa3kfneT6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "corpus->"
      ],
      "metadata": {
        "id": "bnZh1CIboBrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    \"RAG stands for Retrieval-Augmented Generation. It retrieves relevant context before generating answers.\",\n",
        "    \"Vector embeddings map text to vectors so similar meanings are close in space.\",\n",
        "    \"Cosine similarity measures the angle between two vectors to gauge similarity.\",\n",
        "    \"Indexing documents enables fast retrieval of relevant passages for a user query.\"\n",
        "]"
      ],
      "metadata": {
        "id": "iN4nnwmRnijO"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cleaning the text->"
      ],
      "metadata": {
        "id": "wZcMUn72oFYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "    text = text.strip().lower()\n",
        "    if not text:\n",
        "        return []\n",
        "    tokens = re.findall(r\"[a-zA-Z0-9']+\", text)\n",
        "    if not tokens:\n",
        "        tokens = text.split()\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "rRxpdmoSoEgx"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "building a vocab-BoW->"
      ],
      "metadata": {
        "id": "Xmx2ke0goqt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(token for d in docs for token in tokenize(d)))\n",
        "idx = {t: i for i, t in enumerate(vocab)}\n",
        "\n",
        "def bow_embed(text):\n",
        "    vec = np.zeros(len(vocab), dtype=np.float32)\n",
        "    counts = Counter(tokenize(text))\n",
        "    for t, c in counts.items():\n",
        "        if t in idx:\n",
        "            vec[idx[t]] = c\n",
        "    # L2 normalize to help cosine similarity\n",
        "    norm = np.linalg.norm(vec) or 1.0\n",
        "    return vec / norm"
      ],
      "metadata": {
        "id": "dqj-gjt4ojK_"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the index->"
      ],
      "metadata": {
        "id": "UscZoyB7qkaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_vectors = np.stack([bow_embed(d) for d in docs], axis=0)\n",
        "\n",
        "def cosine_sim(a, b):\n",
        "    # a: (n, d), b: (d,)\n",
        "    return a @ b\n",
        "\n",
        "def retrieve(query, k=2):\n",
        "    qv = bow_embed(query)\n",
        "    sims = cosine_sim(doc_vectors, qv)  # (n,)\n",
        "    topk = np.argsort(-sims)[:k]\n",
        "    return [(docs[i], float(sims[i])) for i in topk]"
      ],
      "metadata": {
        "id": "nFiZf0dTqpHz"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Retrieved raw:\", retrieved)\n",
        "print(\"First retrieved item types:\", type(retrieved), type(retrieved))\n",
        "print(\"First retrieved text preview:\", retrieved[:80] if isinstance(retrieved, str) else retrieved)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iit46aGmvSP_",
        "outputId": "9d5b21a3-25fe-4366-be9e-8dc011e806eb"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved raw: [('RAG stands for Retrieval-Augmented Generation. It retrieves relevant context before generating answers.', 0.3922322690486908), ('Vector embeddings map text to vectors so similar meanings are close in space.', 0.0)]\n",
            "First retrieved item types: <class 'list'> <class 'list'>\n",
            "First retrieved text preview: [('RAG stands for Retrieval-Augmented Generation. It retrieves relevant context before generating answers.', 0.3922322690486908), ('Vector embeddings map text to vectors so similar meanings are close in space.', 0.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RL4gKZvVsu9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(query, retrieved):\n",
        "    if not retrieved:\n",
        "        return \"(Demo) No relevant context found.\"\n",
        "\n",
        "    # Take only strings from each (passage, score)\n",
        "    passages = [ (it if isinstance(it, tuple) else it) for it in retrieved ]\n",
        "    # If any passage is a list, join it into a single string\n",
        "    passages = [ (\" \".join(p) if isinstance(p, list) else p) for p in passages ]\n",
        "    passages = [ p for p in passages if isinstance(p, str) and p.strip() ]\n",
        "\n",
        "    if not passages:\n",
        "        return \"(Demo) No relevant context found.\"\n",
        "\n",
        "    first = passages\n",
        "\n",
        "    import re\n",
        "    def tokenize(text):\n",
        "        if not isinstance(text, str):\n",
        "            return []\n",
        "        text = text.strip().lower()\n",
        "        if not text:\n",
        "            return []\n",
        "        toks = re.findall(r\"[a-zA-Z0-9']+\", text)\n",
        "        return toks if toks else text.split()\n",
        "\n",
        "    toks = tokenize(first)\n",
        "    snippet = \", \".join(toks[:25]) if toks else (first.strip()[:100] if first.strip() else \"(no content)\")\n",
        "    return f\"(Demo) Using retrieved context, the answer likely involves: {snippet}\"\n"
      ],
      "metadata": {
        "id": "mOlq7MmJsvSf"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is RAG and how does it help answering questions?\"\n",
        "retrieved = retrieve(query, k=2)\n",
        "\n",
        "print(\"Retrieved:\")\n",
        "for passage, score in retrieved:\n",
        "    print(f\"- {repr(passage)}  (score={score:.3f})\")\n",
        "\n",
        "print(\"\\nAnswer:\")\n",
        "print(generate_answer(query, retrieved))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDxX3iaXs_ju",
        "outputId": "db3fd936-b6b0-4476-fa8e-95d3a033982e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved:\n",
            "- 'RAG stands for Retrieval-Augmented Generation. It retrieves relevant context before generating answers.'  (score=0.392)\n",
            "- 'Vector embeddings map text to vectors so similar meanings are close in space.'  (score=0.000)\n",
            "\n",
            "Answer:\n",
            "(Demo) No relevant context found.\n"
          ]
        }
      ]
    }
  ]
}